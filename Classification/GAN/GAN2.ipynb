{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN2.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XOJ5IwjCs29X","executionInfo":{"status":"ok","timestamp":1626198534530,"user_tz":240,"elapsed":22311,"user":{"displayName":"ANDY WEI","photoUrl":"","userId":"06386501285763888869"}},"outputId":"d33e508a-13de-4af4-e066-271ff28f03f8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3ix1cCAL_QW3","executionInfo":{"status":"ok","timestamp":1626198603578,"user_tz":240,"elapsed":2120,"user":{"displayName":"ANDY WEI","photoUrl":"","userId":"06386501285763888869"}}},"source":["from __future__ import print_function, division\n","from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply, concatenate, Conv2DTranspose\n","from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import UpSampling2D, Conv2D\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.activations import relu, tanh, linear\n","from tensorflow import keras\n","from tensorflow.keras.utils import Progbar\n","import tensorflow as tf\n","\n","from collections import defaultdict\n","import pickle as pickle\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeO1cPYj_YuH","executionInfo":{"status":"ok","timestamp":1626198740625,"user_tz":240,"elapsed":117,"user":{"displayName":"ANDY WEI","photoUrl":"","userId":"06386501285763888869"}}},"source":["np.random.seed(1337)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBMi-_wptfnF","executionInfo":{"status":"ok","timestamp":1626198782733,"user_tz":240,"elapsed":959,"user":{"displayName":"ANDY WEI","photoUrl":"","userId":"06386501285763888869"}}},"source":["class ACGAN():\n","    def __init__(self):\n","\n","        self.img_rows = 112\n","        self.img_cols = 112\n","        self.channels = 3\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.num_classes = 2\n","        self.latent_dim = 20000\n","\n","        optimizer = Adam(0.0002, 0.5)\n","        losses = ['binary_crossentropy', 'sparse_categorical_crossentropy']\n","\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss=losses,optimizer=optimizer,metrics=['accuracy'])\n","\n","        self.generator = self.build_generator()\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,))\n","        img = self.generator([label,noise])\n","\n","        self.discriminator.trainable = False\n","\n","        valid, target_label = self.discriminator(img)\n","\n","        self.combined = Model([label,noise], [valid, target_label])\n","        self.combined.compile(loss=losses,optimizer=optimizer)\n","\n","    def build_generator(self):\n","\n","        noise = Input(shape=(self.latent_dim,))\n","        label = Input(shape=(1,), dtype='int32')\n","\n","        noise_branch = Dense(1024*7*7)(noise)\n","        noise_branch = relu(noise_branch)\n","        noise_branch = Reshape((7, 7, 1024))(noise_branch)\n","        noise_branch = Model(inputs=noise, outputs=noise_branch)\n","\n","        label_branch = Embedding(input_dim=50,output_dim=1)(label)\n","        label_branch = Dense(49,input_shape=(7,7))(label_branch)\n","        label_branch = linear(label_branch)\n","        label_branch = Reshape((7, 7, 1),)(label_branch)\n","        label_branch = Model(inputs=label, outputs=label_branch)\n","\n","        combined = concatenate([noise_branch.output, label_branch.output])\n","\n","        combined = Conv2DTranspose(512, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(256, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(128, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = BatchNormalization(momentum=0)(combined)\n","        combined = relu(combined)\n","\n","        combined = Conv2DTranspose(3, (5,5), strides=(2,2),padding=\"same\")(combined)\n","        combined = tanh(combined)\n","\n","\n","        model = Model(inputs=[label_branch.input, noise_branch.input], outputs=combined)\n","\n","        keras.utils.plot_model(model, \"generateur.png\", show_shapes=True)\n","\n","        return model\n","\n","    def build_discriminator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), input_shape=self.img_shape, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(64, kernel_size=(3,3), strides=(2,2), input_shape=self.img_shape, padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(128, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(256, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Conv2D(512, kernel_size=(3,3), strides=(2,2), padding=\"same\"))\n","        model.add(BatchNormalization(momentum=0))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.5))\n","\n","        model.add(Flatten())\n","\n","        img = Input(shape=self.img_shape)\n","\n","        features = model(img)\n","\n","        validity = Dense(1, activation=\"sigmoid\")(features)\n","        label = Dense(self.num_classes, activation=\"softmax\")(features)\n","\n","        keras.utils.plot_model(model, \"discriminateur.png\", show_shapes=True)\n","\n","        return Model(img, [validity, label])\n","\n","    def train(self, epochs, batch_size=128):\n","\n","        cxr_train = keras.preprocessing.image_dataset_from_directory(\"train\",labels=\"inferred\",batch_size=2084,image_size=(112, 112))\n","        cxr_test = keras.preprocessing.image_dataset_from_directory(\"test\",labels=\"inferred\",batch_size=1800,image_size=(112, 112))\n","\n","        cxr_train_images = []\n","        cxr_train_labels = []\n","        cxr_test_images = []\n","        cxr_test_labels = []\n","\n","        for images, labels in cxr_train:\n","            for i in range(len(images)):\n","              cxr_train_images.append(images[i])\n","              cxr_train_labels.append(labels[i])\n","\n","        for images, labels in cxr_test:\n","            for i in range(len(images)):\n","              cxr_test_images.append(images[i])\n","              cxr_test_labels.append(labels[i])\n","\n","        cxr_train_images = np.array(cxr_train_images)\n","        cxr_train_labels = np.array(cxr_train_labels)\n","        cxr_test_images = np.array(cxr_test_images)\n","        cxr_test_labels = np.array(cxr_test_labels)\n","\n","        X_train = (cxr_train_images.astype(np.float32) - 127.5) / 127.5\n","\n","        X_test = (cxr_test_images.astype(np.float32) - 127.5) / 127.5\n","\n","        nb_train, nb_test = X_train.shape[0], X_test.shape[0]\n","\n","        train_history = defaultdict(list)\n","        test_history = defaultdict(list)\n","\n","        y_train = cxr_train_labels\n","        y_test = cxr_test_labels\n","\n","        for epoch in range(epochs):\n","\n","            print('Epoch {} of {}'.format(epoch + 1, epochs))\n","            nb_batches = int(X_train.shape[0] / batch_size)\n","            progress_bar = Progbar(target=nb_batches)\n","\n","\n","            epoch_gen_loss = []\n","            epoch_disc_loss = []\n","\n","            for index in range(nb_batches):\n","                progress_bar.update(index)\n","\n","                noise = np.random.normal(0, 0.02, (batch_size, self.latent_dim))\n","\n","                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n","                label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n","\n","                sampled_labels = np.random.randint(0, 1, batch_size)\n","\n","                generated_images = self.generator.predict([sampled_labels.reshape((-1, 1)),noise], verbose=0)\n","\n","                X = np.concatenate((image_batch, generated_images))\n","                y = np.array([1] * batch_size + [0] * batch_size)\n","\n","                aux_y = np.concatenate((label_batch, sampled_labels))\n","\n","                epoch_disc_loss.append(self.discriminator.train_on_batch(X, [y, aux_y]))\n","\n","                noise = np.random.normal(0, 0.02, (2 * batch_size, self.latent_dim))\n","                sampled_labels = np.random.randint(0, 1, 2 * batch_size)\n","\n","                trick = np.ones(2 * batch_size)\n","\n","                epoch_gen_loss.append(self.combined.train_on_batch([sampled_labels.reshape((-1, 1)), noise], [trick, sampled_labels]))\n","\n","            print('\\nTesting for epoch {}:'.format(epoch + 1))\n","            noise = np.random.normal(0, 0.02, (nb_test, self.latent_dim))\n","\n","            sampled_labels = np.random.randint(0, 1, nb_test)\n","            generated_images = self.generator.predict([sampled_labels.reshape((-1, 1)), noise], verbose=False)\n","\n","            X = np.concatenate((X_test, generated_images))\n","            y = np.array([1] * nb_test + [0] * nb_test)\n","            aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n","\n","            discriminator_test_loss = self.discriminator.evaluate(X, [y, aux_y], verbose=False)\n","\n","            discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n","\n","            noise = np.random.normal(0, 0.02, (2 * nb_test, self.latent_dim))\n","            sampled_labels = np.random.randint(0, 1, 2 * nb_test)\n","\n","            trick = np.ones(2 * nb_test)\n","\n","            generator_test_loss = self.combined.evaluate([sampled_labels.reshape((-1, 1)),noise],[trick, sampled_labels], verbose=False)\n","\n","            generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n","\n","            train_history['generator'].append(generator_train_loss)\n","            train_history['discriminator'].append(discriminator_train_loss)\n","\n","            test_history['generator'].append(generator_test_loss)\n","            test_history['discriminator'].append(discriminator_test_loss)\n","\n","            print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format('component', *self.discriminator.metrics_names))\n","            print('-' * 65)\n","\n","            ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n","            print(ROW_FMT.format('generator (train)',*train_history['generator'][-1]))\n","            print(ROW_FMT.format('generator (test)',*test_history['generator'][-1]))\n","            print(ROW_FMT.format('discriminator (train)',*train_history['discriminator'][-1]))\n","            print(ROW_FMT.format('discriminator (test)',*test_history['discriminator'][-1]))\n","\n","            if epoch > 2000:\n","                self.generator.save('saved_model/generator_epoch_{0:03d}.hdf5'.format(epoch))\n","\n","            r, c = 2, 2\n","            noise = np.random.normal(0, 0.02, (r * c, self.latent_dim))\n","\n","            sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n","            gen_imgs = self.generator.predict([sampled_labels, noise])\n","            gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","            fig, axs = plt.subplots(r, c)\n","            cnt = 0\n","            for i in range(r):\n","                for j in range(c):\n","                    axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n","                    axs[i,j].axis('off')\n","                    cnt += 1\n","            fig.savefig(\"images/%d.png\" % epoch)\n","            plt.close()\n","\n","        pickle.dump({'train': train_history, 'test': test_history},open('acgan-history.pkl', 'wb'))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"nn5_gFuBAfHq","executionInfo":{"status":"ok","timestamp":1626198933726,"user_tz":240,"elapsed":14467,"user":{"displayName":"ANDY WEI","photoUrl":"","userId":"06386501285763888869"}}},"source":["acgan = ACGAN()\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0zVVTocAmk1"},"source":["#acgan.train(epochs=2200, batch_size=64)"],"execution_count":null,"outputs":[]}]}